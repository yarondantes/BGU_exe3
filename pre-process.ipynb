{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c2f7e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pickle\n",
    "import glob\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "# from torchvision.models.vgg.V import VGG19_Weights\n",
    "import warnings \n",
    "import os\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import cv2\n",
    "from mat4py import loadmat\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a6d5772",
   "metadata": {},
   "source": [
    "### define different paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "33d18825",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = os.path.dirname(os.path.abspath('__file__'))\n",
    "# data_path = os.path.join(base_path, 'data','data_for_vgg')\n",
    "data_path = os.path.join(base_path, 'data','data_for_vgg_augmented')\n",
    "train_path = os.path.join(data_path,'train')\n",
    "test_path = os.path.join(data_path,'test')\n",
    "labels_file = os.path.join(base_path,'data')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b969d9",
   "metadata": {},
   "source": [
    "### load additional data (classes names, labels, pre-defined data splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "69419739",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('classes.txt', 'rb') as f:\n",
    "    classes = pickle.load(f)\n",
    "\n",
    "labels = loadmat(labels_file+'\\\\imagelabels.mat')\n",
    "data_splits = loadmat(data_path+'\\\\setid.mat')\n",
    "\n",
    "len(data_splits['trnid']), len(data_splits['valid']), len(data_splits['tstid'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "648acd49",
   "metadata": {},
   "source": [
    "## set the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f3d4567",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.loadtxt('labels.csv', dtype=\"int\") # created from original \"imagelabels.mat\" file\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2980ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_name_dict = {num:name for num, name in enumerate(classes)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97944f19",
   "metadata": {},
   "source": [
    "### split images to different folders (by class name) - as prep for pytorch ImageFolder method "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fecf010d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for label, file_path in zip(labels, glob.glob('C:\\\\Users\\\\yaron\\\\projects\\\\BGU-lior_rokach\\\\exe3\\\\data\\\\images\\\\*.jpg')):\n",
    "    file_name = file_path.split('\\\\')[-1]\n",
    "    dest = os.path.join(vgg_data_folder, label_name_dict[label-1],file_name)\n",
    "    shutil.copyfile(file_path,dest)               \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4524ed0b",
   "metadata": {},
   "source": [
    "### train-test split - 50%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1feac6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(train_path, test_path):\n",
    "    print('splitting the data')\n",
    "    test_ratio = 0.5\n",
    "    images_classes_dict = {}\n",
    "    num_of_rec = []\n",
    "    classes = []\n",
    "    for f_class in os.listdir(train_path):\n",
    "        class_path = os.path.join(train_path, f_class)\n",
    "        files = [entry for entry in os.listdir(class_path) if entry.startswith('image')]\n",
    "        num_of_records = len(files)   \n",
    "        num_of_files_to_be_moved = int(np.round(num_of_records * test_ratio))\n",
    "\n",
    "        files_to_be_moved = np.random.choice(files, size=num_of_files_to_be_moved, replace=False)\n",
    "\n",
    "        for f in files_to_be_moved:    \n",
    "            src_path = os.path.join(class_path, f)\n",
    "            dst_path = os.path.join(test_path, f_class)\n",
    "            if not os.path.exists(dst_path):\n",
    "                os.mkdir(dst_path)\n",
    "            num_of_files_in_dst = len([entry for entry in os.listdir(dst_path)])\n",
    "            if num_of_files_in_dst < num_of_files_to_be_moved:\n",
    "                shutil.move(src_path, os.path.join(dst_path),f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54aa78a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_data(train_path, test_path):\n",
    "    print('re-setting the data')\n",
    "    for f_class in os.listdir(test_path):\n",
    "        class_path = os.path.join(test_path, f_class)\n",
    "        files = [entry for entry in os.listdir(class_path)]\n",
    "        \n",
    "        for f in files:    \n",
    "            src_path = os.path.join(class_path, f)\n",
    "            dst_path = os.path.join(train_path, f_class, f)\n",
    "\n",
    "            shutil.move(src_path, os.path.join(dst_path),f)\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "601141ea",
   "metadata": {},
   "source": [
    "### Augmenting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d8c8220",
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage.io as io\n",
    "from skimage.transform import rotate, AffineTransform, warp\n",
    "from skimage.util import random_noise\n",
    "from skimage.filters import gaussian"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d68e4a12",
   "metadata": {},
   "source": [
    "### utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb0358cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut_out(img):\n",
    "    num_of_cutoff_cubes = np.random.randint(2,10)\n",
    "    for _ in range(num_of_cutoff_cubes):\n",
    "        witdh = 70\n",
    "        hight = 70\n",
    "        x_start = np.random.randint(0,img.shape[0]-witdh)\n",
    "        y_start = np.random.randint(0,img.shape[1]-hight)\n",
    "        img[x_start:x_start+witdh,y_start:y_start+hight] = 0\n",
    "    return img "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6600bb2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotate_image(img):\n",
    "    angle = np.random.randint(30,90)\n",
    "    return rotate(img, angle=angle, mode = 'wrap', preserve_range= True).astype('uint8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d249a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tranlation(img):\n",
    "    percent_of_x = np.random.randint(10, 30)\n",
    "    percent_of_y = np.random.randint(10, 30)\n",
    "    num_of_pixs_x = int(img.shape[0] * percent_of_x / 100)\n",
    "    num_of_pixs_y = int(img.shape[1] * percent_of_y / 100)\n",
    "    transform = AffineTransform(translation=(num_of_pixs_x,num_of_pixs_y))\n",
    "    return warp(cv_img,transform,mode='wrap',preserve_range=True).astype('uint8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197be280",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_img_with_prefix(file_name, prefix, path, img):\n",
    "    file_name = prefix + '_' + file_name\n",
    "    cv2.imwrite(os.path.join(path,file_name), img)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2100e18",
   "metadata": {},
   "source": [
    "### create augment script (produces 6 addtional images from each image)\n",
    "* i could mix different changes, but i choose to perform them seperatly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f6aa84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_images(train_path):\n",
    "    for class_name in os.listdir(train_path):\n",
    "        class_path = os.path.join(train_path,class_name)\n",
    "        if os.path.isdir(class_path):\n",
    "            for file_name in os.listdir(class_path):\n",
    "\n",
    "                # load original train image\n",
    "                cv_img = cv2.imread(os.path.join(class_path, file_name))\n",
    "\n",
    "                # rotate image\n",
    "                rotated = rotate_image(cv_img)\n",
    "                save_img_with_prefix(file_name, 'rotated', class_path, rotated)\n",
    "\n",
    "                # translation \n",
    "                wrapShift = tranlation(cv_img)\n",
    "                save_img_with_prefix(file_name, 'wrapShift', class_path, wrapShift)\n",
    "\n",
    "                # flip image left right \n",
    "                flipLR = np.fliplr(cv_img)\n",
    "                save_img_with_prefix(file_name, 'flipLR', class_path, flipLR)\n",
    "\n",
    "                # flip image upside down \n",
    "                flipUD = np.flipud(cv_img)\n",
    "                save_img_with_prefix(file_name, 'flipUD', class_path, flipUD)\n",
    "\n",
    "                # add random noise to the image\n",
    "                sigma=0.155\n",
    "                noisyRandom = random_noise(cv_img,var=sigma**2,)\n",
    "                noisyRandom = (noisyRandom *255 ).astype('uint8')\n",
    "                save_img_with_prefix(file_name, 'gaussian_noise', class_path, noisyRandom)\n",
    "\n",
    "                # cutout\n",
    "                cutout_img = cut_out(cv_img)\n",
    "                save_img_with_prefix(file_name, 'cut_out', class_path, cutout_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14dfcd99",
   "metadata": {},
   "source": [
    "### function to delete augmented images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9079f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_all_augmented(train_path):\n",
    "    print(f'deleting all augmented files')\n",
    "    for class_name in os.listdir(train_path):\n",
    "        class_path = os.path.join(train_path,class_name)\n",
    "        if os.path.isdir(class_path):\n",
    "            for file_name in os.listdir(class_path):\n",
    "                if not file_name.startswith('image'):\n",
    "                    image_path = os.path.join(class_path,file_name)\n",
    "                    os.remove(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83270b81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2175e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d14f1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "08e85fc8",
   "metadata": {},
   "source": [
    "## prepare the data for yolo \"detection\" format (with Bounding Box)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae817e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.path.join(base_path, 'data','data_for_yolo')\n",
    "seg_path = os.path.join(data_path, 'segmim')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c897c152",
   "metadata": {},
   "source": [
    "### utilities functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "225a0c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_rect(img, cords):\n",
    "    img = cv2.rectangle(img, (cords[0],cords[1]), (cords[2],cords[3]), (0,255,0))\n",
    "    cv2.imshow('image',img)\n",
    "    key = cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "def get_file_name_file_num(f):\n",
    "    f_name =  f.split('_')[1]\n",
    "    f_name = f_name.split('.')[0]\n",
    "    f_num = int(f_name)\n",
    "    return f_num, 'image_' + f_name + '.txt'\n",
    "\n",
    "\n",
    "def get_rec_cords(img):\n",
    "    i_min = img.shape[0]\n",
    "    j_min = img.shape[1]\n",
    "    i_max = 0\n",
    "    j_max = 0\n",
    "    \n",
    "    for i in range(img.shape[0]):\n",
    "        for j in range(img.shape[1]): \n",
    "            if any(img[i,j] != np.array([254,0,0],dtype='uint8')):\n",
    "                if i > i_max:\n",
    "                    i_max = i\n",
    "                if i < i_min:\n",
    "                    i_min = i\n",
    "                if j > j_max:\n",
    "                    j_max = j\n",
    "                if j < j_min:\n",
    "                    j_min = j\n",
    "\n",
    "    return j_min, i_min, j_max, i_max\n",
    "\n",
    "def change_to_yolo_format(img, j_min, i_min, j_max, i_max):\n",
    "    j_min = j_min / img.shape[1]\n",
    "    j_max = j_max / img.shape[1]\n",
    "    i_min = i_min / img.shape[0]\n",
    "    i_max = i_max / img.shape[0]\n",
    "    \n",
    "    j_center = (j_max + j_min) / 2\n",
    "    i_center = (i_max + i_min) / 2\n",
    "    \n",
    "    witdh = j_max - j_min\n",
    "    height = i_max - i_min\n",
    "    \n",
    "    return j_center, i_center, witdh, height"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a8f841c",
   "metadata": {},
   "source": [
    "### create label txt files (with BB coordinates) in yolo format \n",
    "* while documenting list of files without usfull segemnts (no BB)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb0f951",
   "metadata": {},
   "source": [
    "#### this phase was eventually truncated due to the fact that there is a \"yolov5 classification only\" option"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23fa3d66",
   "metadata": {},
   "source": [
    "#### create label txt files with Bounding Box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a1bf8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_files_list = []\n",
    "for num,f in enumerate(os.listdir(seg_path)):\n",
    "   \n",
    "    f_num, f_name  = get_file_name_file_num(f)\n",
    "\n",
    "    img = cv2.imread(os.path.join(seg_path,f))\n",
    "\n",
    "    j_min, i_min, j_max, i_max = get_rec_cords(img)\n",
    "\n",
    "    j_center, i_center, witdh, height = change_to_yolo_format(img, j_min, i_min, j_max, i_max)\n",
    "    \n",
    "    if (witdh <= 0) | (height <= 0):\n",
    "        bad_files_list.append(f_name)\n",
    "\n",
    "    line = f\"{labels[f_num]-1} {j_center} {i_center} {witdh} {height}\"\n",
    "\n",
    "    with open(os.path.join(labels_path,f_name),'w') as f:\n",
    "        f.write(line)\n",
    "    \n",
    "    print('image_' + f.split('_')[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea6501bb",
   "metadata": {},
   "source": [
    "### remove \"bad\" images (with no segments, and therefor no BB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd2c6a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_path = os.path.join(data_path, 'images')\n",
    "labels_path = os.path.join(data_path, 'labels')\n",
    "\n",
    "data_path = os.path.join(base_path, 'data','data_for_yolo')\n",
    "no_seg_path = os.path.join(data_path,'images_with_no_segments')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6228a27d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for f_name in bad_files_list[1:]:\n",
    "    src = os.path.join(labels_path, f_name)\n",
    "    dst = os.path.join(no_seg_path, f_name)\n",
    "    shutil.move(src, dst)\n",
    "\n",
    "    f_name = f_name.split('.')[0] + '.jpg'\n",
    "    src = os.path.join(images_path, f_name)\n",
    "    dst = os.path.join(no_seg_path, f_name)\n",
    "    shutil.move(src, dst)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6838aaaa",
   "metadata": {},
   "source": [
    "### split the data to train/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b177c347",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data():\n",
    "    print('splitting the data')\n",
    "    test_ratio = 0.5\n",
    "    \n",
    "    base_path = os.path.dirname(os.path.abspath('__file__'))\n",
    "    data_path = os.path.join(base_path, 'data','data_for_yolo')\n",
    "    \n",
    "    train_path = os.path.join(data_path,'train')\n",
    "    test_path = os.path.join(data_path,'test')\n",
    "    \n",
    "    \n",
    "    files_train = [entry for entry in os.listdir(os.path.join(train_path, 'images'))]\n",
    "    num_of__train_samples = len(files_train)\n",
    "\n",
    "\n",
    "    num_of_files_to_be_moved = int(np.round(num_of__train_samples * test_ratio))\n",
    "    files_to_be_moved = np.random.choice(files_train, size=num_of_files_to_be_moved, replace=False)\n",
    "    labels_to_be_removed = [get_file_name_file_num(f)[1] for f in files_to_be_moved]\n",
    "\n",
    "    files_test = [entry for entry in os.listdir(os.path.join(test_path, 'images'))]\n",
    "    num_of_test_samples = len(files_test)\n",
    "\n",
    "    if num_of_test_samples < num_of_files_to_be_moved:\n",
    "        for file in files_to_be_moved:\n",
    "            _, label_to_be_removed = get_file_name_file_num(file)\n",
    "\n",
    "            src_file = os.path.join(train_path, 'images', file)\n",
    "            dst_file = os.path.join(test_path, 'images', file)\n",
    "            shutil.move(src_file, dst_file)\n",
    "            src_file = os.path.join(train_path, 'labels', label_to_be_removed)\n",
    "            dst_file = os.path.join(test_path, 'labels', label_to_be_removed)\n",
    "            shutil.move(src_file, dst_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed5b6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_data():\n",
    "    print('resetting the data')\n",
    "    base_path = os.path.dirname(os.path.abspath('__file__'))\n",
    "    data_path = os.path.join(base_path, 'data','data_for_yolo')\n",
    "    \n",
    "    train_path = os.path.join(data_path,'train')\n",
    "    test_path = os.path.join(data_path,'test')\n",
    "    \n",
    "    for file in os.listdir(os.path.join(test_path,'images')):\n",
    "        _, label_file = get_file_name_file_num(file)\n",
    "\n",
    "        src_file = os.path.join(test_path, 'images', file)\n",
    "        dst_file = os.path.join(train_path, 'images', file)\n",
    "        shutil.move(src_file, dst_file)\n",
    "        src_file = os.path.join(test_path, 'labels', label_file)\n",
    "        dst_file = os.path.join(train_path, 'labels', label_file)\n",
    "        shutil.move(src_file, dst_file)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4250fd07",
   "metadata": {},
   "source": [
    "### making list of classes for yolo yaml format (to be added to yaml file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "428650c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: pink primrose\n",
      " 1: hard-leaved pocket orchid\n",
      " 2: canterbury bells\n",
      " 3: sweet pea\n",
      " 4: english marigold\n",
      " 5: tiger lily\n",
      " 6: moon orchid\n",
      " 7: bird of paradise\n",
      " 8: monkshood\n",
      " 9: globe thistle\n",
      " 10: snapdragon\n",
      " 11: \"colts foot\"\n",
      " 12: king protea\n",
      " 13: spear thistle\n",
      " 14: yellow iris\n",
      " 15: globe-flower\n",
      " 16: purple coneflower\n",
      " 17: peruvian lily\n",
      " 18: balloon flower\n",
      " 19: giant white arum lily\n",
      " 20: fire lily\n",
      " 21: pincushion flower\n",
      " 22: fritillary\n",
      " 23: red ginger\n",
      " 24: grape hyacinth\n",
      " 25: corn poppy\n",
      " 26: prince of wales feathers\n",
      " 27: stemless gentian\n",
      " 28: artichoke\n",
      " 29: sweet william\n",
      " 30: carnation\n",
      " 31: garden phlox\n",
      " 32: love in the mist\n",
      " 33: mexican aster\n",
      " 34: alpine sea holly\n",
      " 35: ruby-lipped cattleya\n",
      " 36: cape flower\n",
      " 37: great masterwort\n",
      " 38: siam tulip\n",
      " 39: lenten rose\n",
      " 40: barbeton daisy\n",
      " 41: daffodil\n",
      " 42: sword lily\n",
      " 43: poinsettia\n",
      " 44: bolero deep blue\n",
      " 45: wallflower\n",
      " 46: marigold\n",
      " 47: buttercup\n",
      " 48: oxeye daisy\n",
      " 49: common dandelion\n",
      " 50: petunia\n",
      " 51: wild pansy\n",
      " 52: primula\n",
      " 53: sunflower\n",
      " 54: pelargonium\n",
      " 55: bishop of llandaff\n",
      " 56: gaura\n",
      " 57: geranium\n",
      " 58: orange dahlia\n",
      " 59: pink-yellow dahlia\n",
      " 60: cautleya spicata\n",
      " 61: japanese anemone\n",
      " 62: black-eyed susan\n",
      " 63: silverbush\n",
      " 64: californian poppy\n",
      " 65: osteospermum\n",
      " 66: spring crocus\n",
      " 67: bearded iris\n",
      " 68: windflower\n",
      " 69: tree poppy\n",
      " 70: gazania\n",
      " 71: azalea\n",
      " 72: water lily\n",
      " 73: rose\n",
      " 74: thorn apple\n",
      " 75: morning glory\n",
      " 76: passion flower\n",
      " 77: lotus\n",
      " 78: toad lily\n",
      " 79: anthurium\n",
      " 80: frangipani\n",
      " 81: clematis\n",
      " 82: hibiscus\n",
      " 83: columbine\n",
      " 84: desert-rose\n",
      " 85: tree mallow\n",
      " 86: magnolia\n",
      " 87: cyclamen\n",
      " 88: watercress\n",
      " 89: canna lily\n",
      " 90: hippeastrum\n",
      " 91: bee balm\n",
      " 92: ball moss\n",
      " 93: foxglove\n",
      " 94: bougainvillea\n",
      " 95: camellia\n",
      " 96: mallow\n",
      " 97: mexican petunia\n",
      " 98: bromelia\n",
      " 99: blanket flower\n",
      " 100: trumpet creeper\n",
      " 101: blackberry lily}\n"
     ]
    }
   ],
   "source": [
    "print(str({int: clas for int, clas in enumerate(classes, start=0)}).replace(\"'\",\"\").replace(\",\",\"\\n\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c79e39",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle",
   "language": "python",
   "name": "kaggle"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
